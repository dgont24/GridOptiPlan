{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandapower as pp\n",
    "from pandapower.control import ConstControl\n",
    "from pandapower.timeseries import DFData\n",
    "from pandapower.timeseries import OutputWriter\n",
    "from pandapower.timeseries.run_time_series import run_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS = 35040 # 365 days with 15min resolution\n",
    "V_REF = 1.0 # pu\n",
    "V_NOM = 416 # V\n",
    "\n",
    "CURRENT_SCENARIO = 'initial'\n",
    "\n",
    "working_folder = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(working_folder, os.pardir))\n",
    "network_path = os.path.join(root_dir, 'data', CURRENT_SCENARIO,'network')\n",
    "data_path = os.path.join(root_dir, 'data', CURRENT_SCENARIO)\n",
    "\n",
    "# load network\n",
    "net = pp.from_json(os.path.join(network_path,'IEEE_modified_LV_Feeder.json'))\n",
    "# load required dataframes\n",
    "# aggregate node consumption/generation data\n",
    "aggregate_node_data = pd.read_csv(os.path.join(data_path,\"aggregate_node_info.csv\"))\n",
    "generators_df = pd.read_csv(os.path.join(data_path,\"pv_data\",\"pv_info.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data source\n",
    "\n",
    "Data taken from csv data provided in IEEE benchmark grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_load_data_source(aggregate_df, data_path):\n",
    "    profiles = pd.DataFrame()\n",
    "    for i, row in aggregate_df.iterrows():\n",
    "        # add yealy load profile\n",
    "        load_file_path = os.path.join(data_path,\"load_data\",\"15min\",row['load_profile_name'])\n",
    "        load_profile = pd.read_csv(load_file_path).consumption_kW.values * 1e-3  # read in mw\n",
    "\n",
    "        # add yearly ev profile\n",
    "        ev_profile = [0] * len(load_profile)\n",
    "        if pd.notna(row['ev_profile_name']):\n",
    "            ev_file_path = os.path.join(data_path,\"ev_data\",\"15min\",row['ev_profile_name'])\n",
    "            ev_profile = pd.read_csv(ev_file_path).charging_power_kW.values * 1e-3  # read in mw \n",
    "\n",
    "        profiles[row['load_name'] + '_P'] = np.add(load_profile, ev_profile)\n",
    "        \n",
    "        # add reactive power column\n",
    "        profiles[row['load_name'] + '_Q'] = 0 \n",
    "\n",
    "    ds = DFData(profiles)\n",
    "    return profiles, ds\n",
    "\n",
    "def create_gen_data_source(gens_df, data_path):\n",
    "# carefull data is in watt\n",
    "    profiles = pd.DataFrame()    \n",
    "    for id, filepath in (gens_df[['id','profile_name']].values):        \n",
    "        profiles['PV' + str(id) + '_P'] = pd.read_csv(os.path.join(data_path,\"pv_data\",\"15min\",filepath)).p_w.values * 1e-6  # read in mw\n",
    "        \n",
    "    profiles['PV_Q'] = 0\n",
    "\n",
    "    ds = DFData(profiles)\n",
    "    return profiles, ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series controller\n",
    "\n",
    "P, Q values entered using P and power factor(cos_phi) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_load_controllers(net, aggregate_df, ds):\n",
    "    ConstControl(net, element='load', variable='p_mw', element_index=aggregate_df.index,\n",
    "                 data_source=ds, profile_name=aggregate_df.load_name+'_P')\n",
    "    ConstControl(net, element='load', variable='q_mvar', element_index=aggregate_df.index,\n",
    "                 data_source=ds, profile_name=aggregate_df.load_name+'_Q')\n",
    "    return net\n",
    "\n",
    "def create_gen_controllers(net, gens_df, ds):\n",
    "    ConstControl(net, element='sgen', variable='p_mw', element_index=gens_df.index,\n",
    "                 data_source=ds, profile_name='PV'+gens_df['id'].astype(str)+'_P')\n",
    "    ConstControl(net, element='sgen', variable='q_mvar', element_index=gens_df.index,\n",
    "                 data_source=ds, profile_name='PV_Q')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format output\n",
    "\n",
    "- Bus voltage magnitudes and angles for each time step\n",
    "- Aggregated Sum of P & Q values for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_writer(net, time_steps, output_dir):\n",
    "    ow = OutputWriter(net, time_steps, output_path=output_dir, output_file_type=\".json\")\n",
    "    ow.log_variable('res_trafo', 'p_lv_mw', index=net.trafo.index)\n",
    "    ow.log_variable('res_trafo', 'q_lv_mvar', index=net.trafo.index)\n",
    "    ow.log_variable('res_bus', 'vm_pu')\n",
    "    ow.log_variable('res_bus', 'va_degree')\n",
    "    ow.log_variable('res_line', 'loading_percent')\n",
    "    return ow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_calculation(net, n_timesteps, output_dir, aggregate_df, gens_df, data_path):\n",
    "    # create data source\n",
    "    load_profiles, ds_load = create_load_data_source(aggregate_df, data_path)\n",
    "    sgen_profiles, ds_sgen = create_gen_data_source(gens_df, data_path)\n",
    "\n",
    "    # create controllers (to control P values of the load and the sgen)\n",
    "    create_load_controllers(net, aggregate_df, ds_load)\n",
    "    create_gen_controllers(net, gens_df, ds_sgen)\n",
    "\n",
    "    # time steps to be calculated. Could also be a list with non-consecutive time steps\n",
    "    time_steps = range(0, n_timesteps)\n",
    "\n",
    "    # 4. the output writer with the desired results to be stored to files.\n",
    "    ow = create_output_writer(net, time_steps, output_dir=output_dir)\n",
    "\n",
    "    # 5. the main time series function\n",
    "    run_timeseries(net, time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results can be found in data folder: c:\\Users\\dgont\\OneDrive\\Documents\\VScode\\GridOptiPlan\\data\\initial\\time_series_calculation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_P'] = np.add(load_profile, ev_profile)\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_Q'] = 0\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_P'] = np.add(load_profile, ev_profile)\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_Q'] = 0\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_P'] = np.add(load_profile, ev_profile)\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_Q'] = 0\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_P'] = np.add(load_profile, ev_profile)\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_Q'] = 0\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_P'] = np.add(load_profile, ev_profile)\n",
      "C:\\Users\\dgont\\AppData\\Local\\Temp\\ipykernel_31864\\2917488755.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  profiles[row['load_name'] + '_Q'] = 0\n",
      "100%|██████████| 35040/35040 [06:18<00:00, 92.51it/s] \n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(data_path, \"time_series_calculation\")\n",
    "print(\"Results can be found in data folder: {}\".format(output_dir))\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "timeseries_calculation(net, TIMESTEPS, output_dir, aggregate_node_data, generators_df, data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
